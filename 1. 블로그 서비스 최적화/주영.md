## 1️⃣ 이미지 CDN
### 1.상황
원래 이미지의 사이즈보다 큰 크기의 이미지를 다운로드한다면, 이미지 파일을 불러오는 시간이 오래걸릴 것이다.  
이 때, 이미지 CDN을 사용하면 물리적 거리는 줄이면서 사이즈와 포멧을 최적화할 수 있다.
### 2. 방법
**Imgix CDN을 적용해 사이즈를 줄이면서 최신 포멧을 적용할 수 있다.**
- 적절한 이미지 사이즈 요청 : 최대 2배의 사이즈까지 가져옴
- 차세대 포멧 자동 변환 : WebP 또는 AVIF 변환
- 자동 압축


💬 그렇다면 렌더링 사이즈(120x120)일 경우 몇으로 가져올까?  
정답은 2배인 240이다. 그 이유는 **Retina 디스플레이와 같은 고해상도 디스플레이를 고려해 2배**로 가져온다.  

**이미지 최적화에서 DPR = 2로 가져오는 이유**  

일단** DPR**이란, 디바이스 픽셀과 CSS 픽셀의 비율이다.  

예를 들어 DPR이 2인 디스플레이는 
- CSS가 1px인 요소를 표현하기 위해 2x2인(총 4개)의 픽셀이 들어가야 한다는 것을 말한다.  
- 즉, 화면의 해상도가 높아보임
- 2배 확대한 상태에서도 선명하게

**그렇다면 3배, 4배가 아닌 2배인 이유는?**
- 기본적으로 널리 보급된 고해상도 디스플레이는 DPR 2인 Retina 디스플레이이기 때문이다.  
- DPR = 3, 4를 고려하기엔, 로딩 성능이 안좋아질 수도 있다.


## 2️⃣ 자바스크립트 코드 최적화
### 1. 상황  
FCP 렌더링 이후, 오랫동안 블로그 컨텐츠가 나오지 않음  
예를 들어, 기사 API를 받아온 후, 어떤 메인 작업(콜백 함수)에 의해 **병목 현상**이 발생  
메인 탭을 보면, ```Article``` > ```removeSpecialCharacter``` 함수가 많은 시간을 잡아먹는 것을 확인  
즉 이 함수가 범인.  
또한 **리소스를 많이 차지하는 함수**이므로, **가비지 컬렉터(Minor GC)**에 의해 쪼개지듯 실행되는 현상이 있었다.  

**문제 코드**
1. str 문자열의 길이가 매우 김 (사실상 화면에 나오는 건 2줄이지만, 엄청 많은 컨텐츠를 로드)  
2. 특수 문자를 제거하는 데, 불필요하게 이중 반복문을 씀  
``` Javascript
/*
 * 파라미터로 넘어온 문자열에서 일부 특수문자를 제거하는 함수
 * (Markdown으로 된 문자열의 특수문자를 제거하기 위함)
 * */
function removeSpecialCharacter(str) {
  const removeCharacters = ["#", "_", "*", "~", "&", ";", "!", "[", "]", "`", ">", "\n", "=", "-"];
  let _str = str;
  let i = 0,
    j = 0;

  for (i = 0; i < removeCharacters.length; i++) {
    j = 0;
    while (j < _str.length) {
      if (_str[j] === removeCharacters[i]) {
        _str = _str.substring(0, j).concat(_str.substring(j + 1));
        continue;
      }
      j++;
    }
  }

  return _str;
}

```

### 해결 방법
1. str 문자열의 길이를 200자로 줄임 ✅
2. 마크다운에서 특수 문자를 제거하기 위해 replace 함수 + 특정 패턴을 찾는 정규식 ✅

```javascript
function removeSpecialCharacter(str) {
  let _str = str.substring(0, 200);
  _str = _str.replace(/[#_*~&;!\[\]`>\n=\-]/g, "");

  return _str;
}
```

## 3️⃣ 페이지 단위 코드 스플리팅(Code Splitting)
**우선 번들 파일을 분석해주는 CRA 라이브러리가 잇다.**
https://www.npmjs.com/package/cra-bundle-analyzer  

### 문제 원인
보다시피, node_modules의 refactor 모듈이 큰 사이즈를 차지하고 있다보니, **번들 크기**가 커졌다.  
이 문제로 인해, 처음 웹사이트를 실행할 때 **초기 로딩 속도가 지연**되었다.  
![image (6)](https://github.com/user-attachments/assets/cde0e362-f5a0-4853-882e-2bba1be5c7fe)  

refactor 모듈은 package-lock.json에서 확인할 수 있었다.   
react-syntax-highlighter의 종속 모듈로써 설치되었는데, 마크다운 언어에 색상 표시를 해주는 라이브러리였다.    
하지만 이는 상세 페이지에서만 쓰이기 때문에 굳이 처음부터 가져오지 않아도 된다.  
cf) ```package-lock.json``` <- 일종의 모듈 명세서  

### 해결 방법
**Code Splitting을 통해 라우트(페이지) 단위로 코드를 분할**하여 불러오므로써, 해결할 수 있었다.  
즉, 해당 페이지에 진입할 때 필요한 모듈이 그 시점에서 동적으로 다운로드 된다.  
이를 통해 전체 번들(bundle)에서 **청크**로 따로 분리되어, 초기 로딩 속도가 빨라진다.  
```javascript
import React, { Suspense, lazy } from "react";
import { Route, Routes } from "react-router-dom";
import "./App.css";
// import ListPage from './pages/ListPage/index';
// import ViewPage from './pages/ViewPage/index';

const ListPage = lazy(() => import("./pages/ListPage/index"));
const ViewPage = lazy(() => import("./pages/ViewPage/index"));

function App() {
  return (
    <div className="App">
      <Suspense fallback={<div>Loading...</div>}>
        <Routes>
          <Route path="/" element={<ListPage />} />
          <Route path="/view/:id" element={<ViewPage />} />
        </Routes>
      </Suspense>
    </div>
  );
}

export default App;

```
## 텍스트 압축  
**번들 파일을 ```gzip```을 통해 압축해서 다운로드 성능을 최적화할 수 있다.**  
하지만, 압축하고 프론트엔드에서 해제하는 데 걸리는 시간이 있기 때문에, 파일의 크기가 너무 작으면 압축을 하지 않는 경우도 있다. (대개 몇 KB 이상)  
